Homework 5
================
Amanda Warnock

This is my solution to HW5.

``` r
library(tidyverse)
```

    ## ── Attaching packages ────────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ───────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(rvest)
```

    ## Loading required package: xml2

    ## 
    ## Attaching package: 'rvest'

    ## The following object is masked from 'package:purrr':
    ## 
    ##     pluck

    ## The following object is masked from 'package:readr':
    ## 
    ##     guess_encoding

``` r
library(ggplot2)
library(data.table)
```

    ## 
    ## Attaching package: 'data.table'

    ## The following objects are masked from 'package:dplyr':
    ## 
    ##     between, first, last

    ## The following object is masked from 'package:purrr':
    ## 
    ##     transpose

``` r
library(patchwork)
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.color = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_color_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d

set.seed(1)
```

## Problem 1

Read in the data.

``` r
homicide_df = 
  read_csv("./data/homicide-data.csv") %>% 
  mutate(
   city_state = str_c(city, state, sep = "_"),
   resolved = case_when(
     disposition == "Closed without arrest" ~ "unsolved",
     disposition == "Open/No arrest"        ~ "unsolved",
     disposition == "Closed by arrest"      ~ "solved"
   ) 
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL")
```

    ## Parsed with column specification:
    ## cols(
    ##   uid = col_character(),
    ##   reported_date = col_double(),
    ##   victim_last = col_character(),
    ##   victim_first = col_character(),
    ##   victim_race = col_character(),
    ##   victim_age = col_character(),
    ##   victim_sex = col_character(),
    ##   city = col_character(),
    ##   state = col_character(),
    ##   lat = col_double(),
    ##   lon = col_double(),
    ##   disposition = col_character()
    ## )

Let’s look at this a bit.

``` r
aggregate_df = 
homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```

    ## `summarise()` ungrouping output (override with `.groups` argument)

Can I do a prop test for a single city?

``` r
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved), 
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>% 
  broom::tidy()
```

    ## # A tibble: 1 x 8
    ##   estimate statistic  p.value parameter conf.low conf.high method    alternative
    ##      <dbl>     <dbl>    <dbl>     <int>    <dbl>     <dbl> <chr>     <chr>      
    ## 1    0.646      239. 6.46e-54         1    0.628     0.663 1-sample… two.sided

Try to iterate …..

``` r
results_df = 
aggregate_df %>% 
  mutate(
    prop_test = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_test = map(.x = prop_test, ~broom::tidy(.x))
  ) %>% 
  select(-prop_test) %>% 
  unnest(tidy_test) %>% 
  select(city_state, estimate, conf.low, conf.high)
```

``` r
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) 
```

<img src="p8105_hw5_aw3251_files/figure-gfm/unnamed-chunk-6-1.png" width="90%" />

## Problem 2

Import the 20 files, clean, and tidy.

``` r
path_df = 
  tibble(
    path = list.files("./lddata")
  ) %>% 
  mutate(
    path = str_c("lddata/", path),
    path_names = path,
    data = map(path, read_csv)
    ) %>% 
  separate(col = path_names, into = c("path_1", "path_2"), sep = 7, remove = T) %>% 
  separate(col = path_2, into = c("arm", "ID"), sep = 3) %>% 
  separate(col = ID, into = c("underscore", "ID"), sep = 1, remove = T) %>% 
  separate(col = ID, into = c("ID", "csv"), sep = 2, remove = T) %>% 
  select(-path_1, -underscore, -csv) %>% 
  mutate(
    arm = str_replace(arm, "con", "Control"),
    arm = str_replace(arm, "exp", "Experiment")) %>% 
  unnest(data) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week", 
    values_to = "observation"
  ) 
```

    ## Parsed with column specification:
    ## cols(
    ##   week_1 = col_double(),
    ##   week_2 = col_double(),
    ##   week_3 = col_double(),
    ##   week_4 = col_double(),
    ##   week_5 = col_double(),
    ##   week_6 = col_double(),
    ##   week_7 = col_double(),
    ##   week_8 = col_double()
    ## )
    ## Parsed with column specification:
    ## cols(
    ##   week_1 = col_double(),
    ##   week_2 = col_double(),
    ##   week_3 = col_double(),
    ##   week_4 = col_double(),
    ##   week_5 = col_double(),
    ##   week_6 = col_double(),
    ##   week_7 = col_double(),
    ##   week_8 = col_double()
    ## )
    ## Parsed with column specification:
    ## cols(
    ##   week_1 = col_double(),
    ##   week_2 = col_double(),
    ##   week_3 = col_double(),
    ##   week_4 = col_double(),
    ##   week_5 = col_double(),
    ##   week_6 = col_double(),
    ##   week_7 = col_double(),
    ##   week_8 = col_double()
    ## )
    ## Parsed with column specification:
    ## cols(
    ##   week_1 = col_double(),
    ##   week_2 = col_double(),
    ##   week_3 = col_double(),
    ##   week_4 = col_double(),
    ##   week_5 = col_double(),
    ##   week_6 = col_double(),
    ##   week_7 = col_double(),
    ##   week_8 = col_double()
    ## )
    ## Parsed with column specification:
    ## cols(
    ##   week_1 = col_double(),
    ##   week_2 = col_double(),
    ##   week_3 = col_double(),
    ##   week_4 = col_double(),
    ##   week_5 = col_double(),
    ##   week_6 = col_double(),
    ##   week_7 = col_double(),
    ##   week_8 = col_double()
    ## )
    ## Parsed with column specification:
    ## cols(
    ##   week_1 = col_double(),
    ##   week_2 = col_double(),
    ##   week_3 = col_double(),
    ##   week_4 = col_double(),
    ##   week_5 = col_double(),
    ##   week_6 = col_double(),
    ##   week_7 = col_double(),
    ##   week_8 = col_double()
    ## )
    ## Parsed with column specification:
    ## cols(
    ##   week_1 = col_double(),
    ##   week_2 = col_double(),
    ##   week_3 = col_double(),
    ##   week_4 = col_double(),
    ##   week_5 = col_double(),
    ##   week_6 = col_double(),
    ##   week_7 = col_double(),
    ##   week_8 = col_double()
    ## )
    ## Parsed with column specification:
    ## cols(
    ##   week_1 = col_double(),
    ##   week_2 = col_double(),
    ##   week_3 = col_double(),
    ##   week_4 = col_double(),
    ##   week_5 = col_double(),
    ##   week_6 = col_double(),
    ##   week_7 = col_double(),
    ##   week_8 = col_double()
    ## )
    ## Parsed with column specification:
    ## cols(
    ##   week_1 = col_double(),
    ##   week_2 = col_double(),
    ##   week_3 = col_double(),
    ##   week_4 = col_double(),
    ##   week_5 = col_double(),
    ##   week_6 = col_double(),
    ##   week_7 = col_double(),
    ##   week_8 = col_double()
    ## )
    ## Parsed with column specification:
    ## cols(
    ##   week_1 = col_double(),
    ##   week_2 = col_double(),
    ##   week_3 = col_double(),
    ##   week_4 = col_double(),
    ##   week_5 = col_double(),
    ##   week_6 = col_double(),
    ##   week_7 = col_double(),
    ##   week_8 = col_double()
    ## )
    ## Parsed with column specification:
    ## cols(
    ##   week_1 = col_double(),
    ##   week_2 = col_double(),
    ##   week_3 = col_double(),
    ##   week_4 = col_double(),
    ##   week_5 = col_double(),
    ##   week_6 = col_double(),
    ##   week_7 = col_double(),
    ##   week_8 = col_double()
    ## )
    ## Parsed with column specification:
    ## cols(
    ##   week_1 = col_double(),
    ##   week_2 = col_double(),
    ##   week_3 = col_double(),
    ##   week_4 = col_double(),
    ##   week_5 = col_double(),
    ##   week_6 = col_double(),
    ##   week_7 = col_double(),
    ##   week_8 = col_double()
    ## )
    ## Parsed with column specification:
    ## cols(
    ##   week_1 = col_double(),
    ##   week_2 = col_double(),
    ##   week_3 = col_double(),
    ##   week_4 = col_double(),
    ##   week_5 = col_double(),
    ##   week_6 = col_double(),
    ##   week_7 = col_double(),
    ##   week_8 = col_double()
    ## )
    ## Parsed with column specification:
    ## cols(
    ##   week_1 = col_double(),
    ##   week_2 = col_double(),
    ##   week_3 = col_double(),
    ##   week_4 = col_double(),
    ##   week_5 = col_double(),
    ##   week_6 = col_double(),
    ##   week_7 = col_double(),
    ##   week_8 = col_double()
    ## )
    ## Parsed with column specification:
    ## cols(
    ##   week_1 = col_double(),
    ##   week_2 = col_double(),
    ##   week_3 = col_double(),
    ##   week_4 = col_double(),
    ##   week_5 = col_double(),
    ##   week_6 = col_double(),
    ##   week_7 = col_double(),
    ##   week_8 = col_double()
    ## )
    ## Parsed with column specification:
    ## cols(
    ##   week_1 = col_double(),
    ##   week_2 = col_double(),
    ##   week_3 = col_double(),
    ##   week_4 = col_double(),
    ##   week_5 = col_double(),
    ##   week_6 = col_double(),
    ##   week_7 = col_double(),
    ##   week_8 = col_double()
    ## )
    ## Parsed with column specification:
    ## cols(
    ##   week_1 = col_double(),
    ##   week_2 = col_double(),
    ##   week_3 = col_double(),
    ##   week_4 = col_double(),
    ##   week_5 = col_double(),
    ##   week_6 = col_double(),
    ##   week_7 = col_double(),
    ##   week_8 = col_double()
    ## )
    ## Parsed with column specification:
    ## cols(
    ##   week_1 = col_double(),
    ##   week_2 = col_double(),
    ##   week_3 = col_double(),
    ##   week_4 = col_double(),
    ##   week_5 = col_double(),
    ##   week_6 = col_double(),
    ##   week_7 = col_double(),
    ##   week_8 = col_double()
    ## )
    ## Parsed with column specification:
    ## cols(
    ##   week_1 = col_double(),
    ##   week_2 = col_double(),
    ##   week_3 = col_double(),
    ##   week_4 = col_double(),
    ##   week_5 = col_double(),
    ##   week_6 = col_double(),
    ##   week_7 = col_double(),
    ##   week_8 = col_double()
    ## )
    ## Parsed with column specification:
    ## cols(
    ##   week_1 = col_double(),
    ##   week_2 = col_double(),
    ##   week_3 = col_double(),
    ##   week_4 = col_double(),
    ##   week_5 = col_double(),
    ##   week_6 = col_double(),
    ##   week_7 = col_double(),
    ##   week_8 = col_double()
    ## )

Make a spaghetti plot showing observations

``` r
path_plot = 
  path_df %>% 
  unite("Arm_ID", arm:ID, sep = "_", remove = FALSE) %>% 
  ggplot(aes(x = week, y = observation, group = Arm_ID, color = arm)) +
  geom_line() +
  labs(title = "Observations per Subject Over Time")

path_plot
```

<img src="p8105_hw5_aw3251_files/figure-gfm/unnamed-chunk-8-1.png" width="90%" />

This plot shows that overall, the observations for the subjects in the
experiment group were higher than the observations for the control
group. Though the starting observations for the subjects were mixed at
week 1, all observations for the experiment group were higher than all
observations for the control group at week 8.

## Problem 3

``` r
sim_ttest = function(n, mu = 0, sigma = 5) {
  
  sim_data = tibble(
    x = rnorm(n = 30, mean = mu, sd = sigma),
  )
  
    ttest=t.test(sim_data, mu=0, sd=5)
    ttest[['p.value']]
    ttest[['estimate']]
    
  sim_results = tibble(
     pvalue = ttest[['p.value']],
     mean = ttest[['estimate']]
  )

}

output = vector("list", 5000)

for (i in 1:5000) {
  output[[i]] = sim_ttest(30) 
}
sim_results = bind_rows(output)
```

Testing the simulation in rerun.

``` r
sim_results1 = 
  rerun(5000, sim_ttest(30, 1, 5)) %>% 
  bind_rows()
```

Simulating across multiple means.

``` r
m_list = 
  list(
    "m_0" = 0,
    "m_1" = 1,
    "m_2" = 2,
    "m_3" = 3,
    "m_4" = 4,
    "m_5" = 5,
    "m_6" = 6
  )

output = vector("list", length = 7)

for (i in 1:7) {
  output[[i]] = rerun(5000, sim_ttest(30, m_list[[i]], 5)) %>% 
    bind_rows()
}
sim_full_results=bind_rows(output) 
```

``` r
sim_full_results = 
  tibble(mus = c(0, 1, 2, 3, 4, 5, 6)) %>% 
  mutate(
    output_lists = map(.x = mus, ~rerun(5000, sim_ttest(30, .x, 5))),
    estimate_dfs = map(output_lists, bind_rows)) %>% 
  select(-output_lists) %>% 
  unnest(estimate_dfs)
```

Plots

``` r
results_df = 
  sim_full_results %>% 
  mutate(
    decision = case_when(
      pvalue >= 0.05 ~ "fail to reject",
      pvalue < 0.05 ~ "reject"
    )
  ) %>% 
  filter(decision == "reject") %>% 
  group_by(mus) %>% 
  summarize(power = n()/5000)
```

    ## `summarise()` ungrouping output (override with `.groups` argument)

``` r
plot_1 =
results_df %>% 
  ggplot(aes(x = mus, y = power)) +
  geom_point() +
  geom_line() +
  labs(
    title = "Proportion of times the null is rejected",
    x = "True Value of Mu",
    y = "Power")

plot_1
```

<img src="p8105_hw5_aw3251_files/figure-gfm/unnamed-chunk-13-1.png" width="90%" />

As the Mu increases from 0 to 6, the proportion of the time that the
null hypothesis is rejected increases. Effect size and power increase
together as we increase Mus.

``` r
plot_all = 
sim_full_results %>% 
  mutate(
    mus = str_c("Mu = ", mus),
    mus = fct_inorder(mus)) %>% 
  ggplot(aes(x = mus, y = mean, fill = mus)) +
  geom_violin() +
  labs(title = "Estimate and Mu in all stamples") +
  stat_summary(fun=mean, geom="point",  size=1)

plot_reject =
sim_full_results %>% 
  mutate(
    mus = str_c("Mu = ", mus),
    mus = fct_inorder(mus)) %>% 
  filter(pvalue < 0.05) %>% 
  ggplot(aes(x = mus, y = mean, fill = mus)) +
  geom_violin() +
  labs(title = "Estimate and Mu only where null is rejected") +
  stat_summary(fun=mean, geom="point", size=1)

plot_all + plot_reject
```

<img src="p8105_hw5_aw3251_files/figure-gfm/unnamed-chunk-14-1.png" width="90%" />

In cases where the null is rejected, the average mu-hat is about equal
to the true value of Mu because the power of the test is so high given
the huge sample size and the large effect size. However, it is more
accurate when the whole sample is included.
